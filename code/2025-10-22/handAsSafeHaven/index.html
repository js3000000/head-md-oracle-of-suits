<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>2D Hand Silhouette Overlay</title>
<style>
  html, body {
    margin: 0; padding: 0; overflow: hidden; height: 100%;
    background: black;
  }
  #videoElement {
    position: fixed;
    top: 0; left: 0;
    width: 100vw; height: 100vh;
    object-fit: cover;
    z-index: 0;
  }
  #overlayCanvas {
    position: fixed;
    top: 0; left: 0;
    width: 100vw; height: 100vh;
    pointer-events: none; /* clicks pass through */
    z-index: 1;
  }
</style>
</head>
<body>

<video id="videoElement" autoplay playsinline muted></video>
<canvas id="overlayCanvas"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<script>
  const video = document.getElementById('videoElement');
  const canvas = document.getElementById('overlayCanvas');
  const ctx = canvas.getContext('2d');

  // Resize canvas to match viewport
  function resizeCanvas() {
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;
  }
  window.addEventListener('resize', resizeCanvas);
  resizeCanvas();

  // Setup MediaPipe Hands
  const hands = new Hands({
    locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
  });

  hands.setOptions({
    maxNumHands: 1,
    modelComplexity: 1,
    minDetectionConfidence: 0.7,
    minTrackingConfidence: 0.5
  });

  hands.onResults(onResults);

  // Setup camera feed
  const camera = new Camera(video, {
    onFrame: async () => {
      await hands.send({image: video});
    },
    width: 640,
    height: 480
  });
  camera.start();

  // Draw the hand silhouette on the canvas
  function onResults(results) {
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (!results.multiHandLandmarks || results.multiHandLandmarks.length === 0) {
      return;
    }

    // We'll draw a polygon connecting landmarks: wrist(0), index_mcp(5), middle_mcp(9), ring_mcp(13), pinky_mcp(17)
    const landmarks = results.multiHandLandmarks[0];

    // Video and canvas may differ in aspect ratio; scale normalized points accordingly:
    const videoWidth = video.videoWidth || 640;
    const videoHeight = video.videoHeight || 480;
    const canvasWidth = canvas.width;
    const canvasHeight = canvas.height;

    // Compute scale factors to map video space to canvas space, preserving aspect ratio
    const scaleX = canvasWidth / videoWidth;
    const scaleY = canvasHeight / videoHeight;

    // MediaPipe normalized coords: x,y in [0,1], origin top-left of video feed

    // Get polygon points
    const polyIndices = [0, 5, 9, 13, 17];

    ctx.lineWidth = 5;
    ctx.strokeStyle = 'lime';
    ctx.fillStyle = 'rgba(0,255,0,0.3)';

    ctx.beginPath();
    for (let i = 0; i < polyIndices.length; i++) {
      const lm = landmarks[polyIndices[i]];
      const x = lm.x * videoWidth * scaleX;
      const y = lm.y * videoHeight * scaleY;

      if (i === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
    }
    // Close polygon back to first point
    const firstLm = landmarks[polyIndices[0]];
    ctx.lineTo(firstLm.x * videoWidth * scaleX, firstLm.y * videoHeight * scaleY);
    ctx.fill();
    ctx.stroke();
  }
</script>

</body>
</html>
